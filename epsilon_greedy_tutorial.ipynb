{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "epsilon_greedy_tutorial",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKeuBhASXa6MOOr+ZcBnHK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xiaocong233/ReinforcementLearning_ML/blob/master/epsilon_greedy_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8uS_JAfWGOn",
        "colab_type": "text"
      },
      "source": [
        "# **Reinforcement Learning Tutorial in Python**\n",
        "###### Created by **Xiaocong Yan** for [StartOnAI](https://startonai.com/)\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA8EDDN0Xtlv",
        "colab_type": "text"
      },
      "source": [
        "## 1. Introduction to RL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JxN8ixlZRc1",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://lilianweng.github.io/lil-log/assets/images/RL_illustration.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70m6nTsAaXFD",
        "colab_type": "text"
      },
      "source": [
        "- What is Reinforcement Learning?\n",
        "  - RL is a subfield in machine learning, it particularly focuses on training AI agents to behave in a certain way by learning directly from its surrounding environment\n",
        "  - Essentially, we are training the agent to choose the optimal action (`a`) given a state (`s`) from the environment that will maxmimizes an engineered reward (`r`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX5hf1YrgCzC",
        "colab_type": "text"
      },
      "source": [
        "- RL Applications\n",
        "  - gameplaying AI\n",
        "    - AlphaGo\n",
        "\n",
        "    <img src=\"https://cdn.geekwire.com/wp-content/uploads/2016/03/160312-go-630x353.jpg\" alt=\"alt text\" width=\"500\" height=\"300\">\n",
        "\n",
        "    - AlphaStar\n",
        "\n",
        "    <img src=\"https://www.version2.dk/sites/v2/files/topillustration/2019/01/alphastarscreenshot.png\" alt=\"alt text\" width=\"600\" height=\"337\">\n",
        "  \n",
        "  - agent in simulation learning to walk\n",
        "  \n",
        "  <img src=\"https://nav74neet.github.io/media/blog/walking.png\" alt=\"alt text\"  width='600' height='250'>\n",
        "\n",
        "  - robots learning to walk\n",
        "\n",
        "    <img src=\"https://www.researchgate.net/profile/Pieter_Jonker/publication/236015074/figure/fig1/AS:299857928572950@1448503109999/a-LEO-a-2D-walking-robot-suitable-for-on-line-Reinforcement-Learning-8-b-Simplest.png\" alt=\"alt text\"  width='340' height='255'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiG2yaOoYwAE",
        "colab_type": "text"
      },
      "source": [
        "## 2. Explore-exploit dilemma and Multi-Armed Bandit Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nUdqjmn4fOf",
        "colab_type": "text"
      },
      "source": [
        "- A fundamental intuition of RL lies within the balancing of explore and exploit\n",
        "- Example: casino multi-armed bandits (slot machines)\n",
        "  ![alt text](https://miro.medium.com/max/1250/1*7axVBpiVF4VQCxxP1UNcnw.png)\n",
        "    - suppose we have three bandits with their own unique probablities of winning the jackpot\n",
        "      - in the start, we have no ideas what the probabilities are\n",
        "      - we want to start playing more: \"explore\" to find the bandit with the highest winning rate as quickly as possible such that we can then \"exploit\" it by playing solely on it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jr07JV7C95k",
        "colab_type": "text"
      },
      "source": [
        "### 2A. Greedy\n",
        "  - drawing upon an updating sample proportion `p_hat` of each bandit (current number of wins / times played on the bandit), a basic greedy algorithm, as its name suggests, will only choose the bandit with the highest current sample proportion\n",
        "  - problem: `p_hat` may be drastically different than the real probability, especially in the beginning where we don't have many samples or times played yet\n",
        "    - if we draw two bandits and one return a win and the other a loss, updating `p_hat` will result in 1 for the victorious bandit and 0 for the losing bandit.\n",
        "      - we will never again choose the losing bandit ever again using greedy algorithm since no matter how many times we update the probability for the victorious bandit, it will never reach below 0\n",
        "      - we will be missing out on exploring the losing bandit at all and choose to solely exploit the winning bandit, when in reality, the unlucky losing bandit may have a much higher real winning probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMz8HXo5HKtI",
        "colab_type": "text"
      },
      "source": [
        "### 2B. Epsilon Greedy\n",
        "  - solution to the greedy problem: adding a chance in each draw, parameterized by variable `epsilon`, where we will choose randomly from all the existing bandits, regardless of their sample proportions\n",
        "  - thus it is created a fundamental algorithm behind RL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYuMPoL-LJdv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "4168b63b-66e3-4f5a-8ba4-31f3d3f3ecdb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# creating the blueprint for a bandit slot machine\n",
        "class Bandit:\n",
        "  def __init__(self, p):\n",
        "    self.p = p # the winning rate\n",
        "    self.p_hat = 0. # sample proportion, or the estimation for the winning rate, intialized to 0\n",
        "    self.n = 0. # number of samples collected\n",
        "\n",
        "  def pull(self):\n",
        "    # draw the virtual bandit with a random probability p and check if won according to the winning rate\n",
        "    # return 1 if won, 0 if lost\n",
        "    return np.random.random() < self.p\n",
        "\n",
        "  def update(self, x):\n",
        "    # increment numbers of samples collected\n",
        "    self.n += 1.\n",
        "    # calculate the new p hat from the previous p hat and the newly obtained value (0 or 1)\n",
        "    self.p_hat = ((self.n - 1) * self.p_hat + x) / self.n\n",
        "\n",
        "def run_simulation(bandits_probs_list, epsilon, n):\n",
        "  # create a list of bandit objects according to their probabilities of win rate\n",
        "  bandits = [Bandit(p) for p in bandits_probs_list]\n",
        "  \n",
        "  # initialize variables\n",
        "  rewards = np.zeros(n)\n",
        "  times_explored = 0\n",
        "  times_exploited = 0\n",
        "  times_optimal_chosen = 0\n",
        "\n",
        "  # selecting the optimal bandit based the highest true probability\n",
        "  optimal_bandit = np.argmax([bandit.p for bandit in bandits])\n",
        "  # print out the true optimal bandit number\n",
        "  print('optimal bandit:', optimal_bandit + 1) # +1 because optimal_bandit is 0 indexed\n",
        "\n",
        "  # use epsilon_greedy to select the next bandit\n",
        "  for i in range(n):\n",
        "    # if probability drawn is smaller than epsilon, randomly select a bandit\n",
        "    if np.random.random() < epsilon:\n",
        "      times_explored += 1\n",
        "      bandit = np.random.randint(len(bandits))\n",
        "    # else selecting the bandit with the highest p_hat\n",
        "    else:\n",
        "      times_exploited += 1\n",
        "      bandit = np.argmax([bandit.p_hat for bandit in bandits])\n",
        "                         \n",
        "    # check if the bandit chosen is actually the optimal bandit\n",
        "    if bandit == optimal_bandit:\n",
        "      # update the correct action count\n",
        "      times_optimal_chosen += 1\n",
        "\n",
        "    # pull the arm for the bandit selected\n",
        "    x = bandits[bandit].pull()\n",
        "\n",
        "    # update rewards logs and sample proportion estimates accordingly\n",
        "    rewards[i] = x\n",
        "    bandits[bandit].update(x)     \n",
        "  \n",
        "  # print proportion estimates for each bandit\n",
        "  for i, bandit in enumerate(bandits):\n",
        "    print(f'bandit{i + 1} estimate win-rate: {round(bandit.p_hat, 3)} | true win_rate: {bandit.p}')\n",
        "\n",
        "  # print total reward\n",
        "  print()\n",
        "  print('total reward:', rewards.sum())\n",
        "  print('overall win-rate:', rewards.sum() / n)\n",
        "  print('explore count:', times_explored)\n",
        "  print('exploit count:', times_exploited)\n",
        "  print('optimal selection count:', times_optimal_chosen)\n",
        "  print('optimal selection rate:', times_optimal_chosen / n)\n",
        "\n",
        "  # plot the results\n",
        "  cumulative_rewards = np.cumsum(rewards)\n",
        "  win_rates = cumulative_rewards / (np.arange(n) + 1)\n",
        "  plt.plot(win_rates)\n",
        "  plt.plot(np.ones(n) * np.max(bandits_probs_list))\n",
        "  plt.title('cumulative win-rate over time')\n",
        "  plt.xlabel('number of trials')\n",
        "  plt.ylabel('win-rate')\n",
        "  plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # simulate a multi-armed bandit problem with 4 machines with win-rates 0, 0.25, 0.5, 0.75\n",
        "  # default random selection to happen 10% of the time, thus epsilon of 0.1\n",
        "  # default to 10000 trials\n",
        "  run_simulation([0, 0.25, 0.5, 0.75], 0.1, 10000)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "optimal bandit: 4\n",
            "bandit1 estimate win-rate: 0.0 | true win_rate: 0\n",
            "bandit2 estimate win-rate: 0.264 | true win_rate: 0.25\n",
            "bandit3 estimate win-rate: 0.496 | true win_rate: 0.5\n",
            "bandit4 estimate win-rate: 0.746 | true win_rate: 0.75\n",
            "\n",
            "total reward: 6995.0\n",
            "overall win-rate: 0.6995\n",
            "explore count: 967\n",
            "exploit count: 9033\n",
            "optimal selection count: 8849\n",
            "optimal selection rate: 0.8849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-qJBTOpXM7u",
        "colab_type": "text"
      },
      "source": [
        "## Sources:"
      ]
    }
  ]
}