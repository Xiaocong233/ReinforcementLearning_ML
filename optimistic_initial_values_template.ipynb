{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimistic_initial_values_template",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IYVV6uAMN1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class Bandit:\n",
        "  def __init__(self, p):\n",
        "    self.p = p # the winning rate\n",
        "    self.p_estimate = 5. # estimation of the winning rate, intialized to 5, an extremely high value\n",
        "    self.N = 1. # number of samples collected, initialized to 1 due to initial p_estimate of 5\n",
        "\n",
        "  def pull(self):\n",
        "    # draw a random probability p and check if won according to the winning rate\n",
        "    return np.random.random() < self.p\n",
        "\n",
        "  def update(self, x):\n",
        "    # increment numbers of samples collected\n",
        "    self.N += 1.\n",
        "    # calculate the new p hat from the previous p hat and the newly obtained value\n",
        "    self.p_estimate = ((self.N - 1) * self.p_estimate + x) / self.N\n",
        "\n",
        "def run_experiment(bandits_probs_list, N):\n",
        "  # create a list of bandit objects according to their probabilities of win rate\n",
        "  bandits = [Bandit(p) for p in bandits_probs_list]\n",
        "  # initialize variables\n",
        "  rewards = np.zeros(N)\n",
        "\n",
        "  for i in range(N):\n",
        "    # use optimistic initial values to select the next bandit\n",
        "    j = np.argmax([b.p_estimate for b in bandits])\n",
        "    # pull the arm for the selected bandit\n",
        "    x = bandits[j].pull()\n",
        "    # update the rewards collection\n",
        "    rewards[i] = x\n",
        "    # update the distribution with the obtained value from the new bandit\n",
        "    bandits[j].update(x)\n",
        "\n",
        "  # print mean estimates for each bandit\n",
        "  for i, b in enumerate(bandits):\n",
        "    print(f'bandit{i + 1} estimate win-rate: {round(b.p_estimate, 3)} | true win_rate: {b.p}')\n",
        "\n",
        "  # print total reward\n",
        "  print()\n",
        "  print('total reward:', rewards.sum())\n",
        "  print('overall win-rate:', rewards.sum() / N)\n",
        "  print('number of times selected each bandit:', [b.N for b in bandits])\n",
        "\n",
        "  # plot the results\n",
        "  cumulative_rewards = np.cumsum(rewards)\n",
        "  win_rates = cumulative_rewards / (np.arange(N) + 1)\n",
        "  plt.ylim([0, 1])\n",
        "  plt.plot(win_rates)\n",
        "  plt.plot(np.ones(N) * np.max(bandits_probs_list))\n",
        "  plt.title('cumulative win-rate over time')\n",
        "  plt.xlabel('number of trials')\n",
        "  plt.ylabel('win-rate')\n",
        "  plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # simulate a multi-armed bandit problem with 5 machines with win-rates 0, 0.25, 0.5, 0.75\n",
        "  # default to 10000 trials\n",
        "  run_experiment([0, 0.25, 0.5, 0.75], 10000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}